{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c84ff721-3ca1-446e-9429-ce890af5a301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘   CORRECTED MULTILINGUAL EVALUATION PIPELINE  v5.3           â•‘\n",
      "â•‘   llama-2-7b-chat-hf | TyDiQA | float16 (no quantization)   â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "    \n",
      "\n",
      "=================================================================\n",
      "ğŸŒ  CORRECTED MULTILINGUAL EVALUATION PIPELINE  v5.3\n",
      "=================================================================\n",
      "\n",
      "â­ Loading meta-llama/Llama-2-7b-chat-hf â€¦\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [06:35<00:00, 197.76s/it]\n",
      "âœ“ Model loaded  |  GPU memory: 13.5 GB\n",
      "\n",
      "ğŸ“š Streaming TyDiQA (primary_task, train split)â€¦\n",
      "`trust_remote_code` is not supported anymore.\n",
      "Please check that the Hugging Face dataset 'google-research-datasets/tydiqa' isn't based on a loading script and remove `trust_remote_code`.\n",
      "If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n",
      "Collecting samples: 21270it [00:09, 2203.56it/s]\n",
      "\n",
      "âœ… Collection complete:\n",
      "   arabic      :  200 answerable samples\n",
      "   bengali     :  200 answerable samples\n",
      "   english     :  200 answerable samples\n",
      "   finnish     :  200 answerable samples\n",
      "   indonesian  :  200 answerable samples\n",
      "   japanese    :  200 answerable samples\n",
      "   korean      :  200 answerable samples\n",
      "   russian     :  200 answerable samples\n",
      "   swahili     :  200 answerable samples\n",
      "   telugu      :  200 answerable samples\n",
      "   thai        :  200 answerable samples\n",
      "\n",
      "ğŸš€ Generating answers  (2200 samples Ã— 4 strategies, batch_size=2)\n",
      "\n",
      "â”€â”€ ARABIC â”€â”€\n",
      "                                                                                \n",
      "â”€â”€ BENGALI â”€â”€\n",
      "                                                                                \n",
      "â”€â”€ ENGLISH â”€â”€\n",
      "                                                                                \n",
      "â”€â”€ FINNISH â”€â”€\n",
      "                                                                                \n",
      "â”€â”€ INDONESIAN â”€â”€\n",
      "                                                                                \n",
      "â”€â”€ JAPANESE â”€â”€\n",
      "                                                                                \n",
      "â”€â”€ KOREAN â”€â”€\n",
      "                                                                                \n",
      "â”€â”€ RUSSIAN â”€â”€\n",
      "                                                                                \n",
      "â”€â”€ SWAHILI â”€â”€\n",
      "                                                                                \n",
      "â”€â”€ TELUGU â”€â”€\n",
      "                                                                                \n",
      "â”€â”€ THAI â”€â”€\n",
      "                                                                                \n",
      "âœ… Generation done.\n",
      "\n",
      "ğŸ“Š Computing metrics (multi-threaded, CPU metrics only)â€¦\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [00:11<00:00,  3.79it/s]\n",
      "âœ… CPU metrics done.\n",
      "\n",
      "ğŸ”¬ Computing BERTScore (sequential GPU pass)â€¦\n",
      "tokenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49.0/49.0 [00:00<00:00, 506kB/s]\n",
      "config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [00:00<00:00, 7.05MB/s]\n",
      "vocab.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 996k/996k [00:00<00:00, 2.19MB/s]\n",
      "tokenizer.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.96M/1.96M [00:00<00:00, 4.64MB/s]\n",
      "model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 714M/714M [00:01<00:00, 416MB/s]\n",
      "âœ… BERTScore done.\n",
      "\n",
      "ğŸ” Error analysisâ€¦\n",
      "âœ… Error analysis done.\n",
      "\n",
      "ğŸ“ˆ Statistical testsâ€¦\n",
      "âœ… Statistical tests done.\n",
      "\n",
      "ğŸ“Š Bootstrap CIsâ€¦\n",
      "âœ… CIs done.\n",
      "\n",
      "ğŸŒ Cross-lingual typological analysisâ€¦\n",
      "   typology_df shape: (44, 12)\n",
      "âœ… Cross-lingual analysis done.\n",
      "\n",
      "ğŸ¨ Generating visualisationsâ€¦\n",
      "âœ… Visualisations saved â†’ /teamspace/studios/this_studio/outputs/viz_20260218_063704\n",
      "\n",
      "=================================================================\n",
      "ğŸ“Š  RESULTS SUMMARY\n",
      "=================================================================\n",
      "\n",
      "â–¸ MINIMAL\n",
      "  arabic       | LMR=1.00 | F1=0.03 | EM=0.00 | TR=0.00 | BS-F1=0.62\n",
      "  bengali      | LMR=0.97 | F1=0.10 | EM=0.00 | TR=0.01 | BS-F1=0.63\n",
      "  english      | LMR=1.00 | F1=0.14 | EM=0.00 | TR=0.01 | BS-F1=0.63\n",
      "  finnish      | LMR=0.98 | F1=0.03 | EM=0.00 | TR=0.01 | BS-F1=0.59\n",
      "  indonesian   | LMR=0.99 | F1=0.11 | EM=0.00 | TR=0.01 | BS-F1=0.62\n",
      "  japanese     | LMR=0.98 | F1=0.07 | EM=0.00 | TR=0.00 | BS-F1=0.59\n",
      "  korean       | LMR=0.99 | F1=0.09 | EM=0.00 | TR=0.00 | BS-F1=0.63\n",
      "  russian      | LMR=0.90 | F1=0.08 | EM=0.00 | TR=0.01 | BS-F1=0.60\n",
      "  swahili      | LMR=0.99 | F1=0.03 | EM=0.00 | TR=0.01 | BS-F1=0.57\n",
      "  telugu       | LMR=0.94 | F1=0.09 | EM=0.00 | TR=0.01 | BS-F1=0.60\n",
      "  thai         | LMR=0.98 | F1=0.18 | EM=0.00 | TR=0.01 | BS-F1=0.59\n",
      "\n",
      "â–¸ EXPLICIT_EN\n",
      "  arabic       | LMR=0.99 | F1=0.03 | EM=0.00 | TR=0.00 | BS-F1=0.62\n",
      "  bengali      | LMR=0.97 | F1=0.09 | EM=0.00 | TR=0.01 | BS-F1=0.63\n",
      "  english      | LMR=1.00 | F1=0.13 | EM=0.00 | TR=0.02 | BS-F1=0.62\n",
      "  finnish      | LMR=0.98 | F1=0.03 | EM=0.00 | TR=0.01 | BS-F1=0.59\n",
      "  indonesian   | LMR=0.98 | F1=0.08 | EM=0.00 | TR=0.00 | BS-F1=0.61\n",
      "  japanese     | LMR=0.97 | F1=0.07 | EM=0.00 | TR=0.00 | BS-F1=0.59\n",
      "  korean       | LMR=0.99 | F1=0.07 | EM=0.00 | TR=0.00 | BS-F1=0.62\n",
      "  russian      | LMR=0.91 | F1=0.08 | EM=0.00 | TR=0.02 | BS-F1=0.60\n",
      "  swahili      | LMR=1.00 | F1=0.03 | EM=0.00 | TR=0.00 | BS-F1=0.57\n",
      "  telugu       | LMR=0.90 | F1=0.08 | EM=0.00 | TR=0.01 | BS-F1=0.60\n",
      "  thai         | LMR=0.98 | F1=0.18 | EM=0.00 | TR=0.00 | BS-F1=0.59\n",
      "\n",
      "â–¸ EXPLICIT_NATIVE\n",
      "  arabic       | LMR=0.99 | F1=0.03 | EM=0.00 | TR=0.00 | BS-F1=0.61\n",
      "  bengali      | LMR=0.97 | F1=0.09 | EM=0.00 | TR=0.01 | BS-F1=0.63\n",
      "  english      | LMR=1.00 | F1=0.15 | EM=0.00 | TR=0.04 | BS-F1=0.63\n",
      "  finnish      | LMR=0.99 | F1=0.03 | EM=0.00 | TR=0.00 | BS-F1=0.59\n",
      "  indonesian   | LMR=0.99 | F1=0.11 | EM=0.00 | TR=0.02 | BS-F1=0.62\n",
      "  japanese     | LMR=1.00 | F1=0.08 | EM=0.00 | TR=0.01 | BS-F1=0.59\n",
      "  korean       | LMR=1.00 | F1=0.10 | EM=0.00 | TR=0.00 | BS-F1=0.64\n",
      "  russian      | LMR=0.93 | F1=0.09 | EM=0.00 | TR=0.02 | BS-F1=0.61\n",
      "  swahili      | LMR=0.99 | F1=0.03 | EM=0.00 | TR=0.01 | BS-F1=0.57\n",
      "  telugu       | LMR=0.94 | F1=0.09 | EM=0.00 | TR=0.01 | BS-F1=0.61\n",
      "  thai         | LMR=1.00 | F1=0.18 | EM=0.00 | TR=0.00 | BS-F1=0.59\n",
      "\n",
      "â–¸ STRICT\n",
      "  arabic       | LMR=0.99 | F1=0.03 | EM=0.00 | TR=0.00 | BS-F1=0.61\n",
      "  bengali      | LMR=0.97 | F1=0.10 | EM=0.00 | TR=0.01 | BS-F1=0.63\n",
      "  english      | LMR=1.00 | F1=0.14 | EM=0.00 | TR=0.07 | BS-F1=0.63\n",
      "  finnish      | LMR=0.99 | F1=0.02 | EM=0.00 | TR=0.00 | BS-F1=0.59\n",
      "  indonesian   | LMR=0.99 | F1=0.05 | EM=0.00 | TR=0.00 | BS-F1=0.60\n",
      "  japanese     | LMR=0.98 | F1=0.07 | EM=0.00 | TR=0.01 | BS-F1=0.59\n",
      "  korean       | LMR=1.00 | F1=0.07 | EM=0.00 | TR=0.00 | BS-F1=0.62\n",
      "  russian      | LMR=0.90 | F1=0.04 | EM=0.00 | TR=0.01 | BS-F1=0.58\n",
      "  swahili      | LMR=0.99 | F1=0.03 | EM=0.00 | TR=0.01 | BS-F1=0.56\n",
      "  telugu       | LMR=0.93 | F1=0.09 | EM=0.00 | TR=0.00 | BS-F1=0.60\n",
      "  thai         | LMR=0.99 | F1=0.18 | EM=0.00 | TR=0.00 | BS-F1=0.59\n",
      "\n",
      "ğŸ’¾ Saving results â†’ /teamspace/studios/this_studio/outputs\n",
      "Traceback (most recent call last):\n",
      "  File \"/teamspace/studios/this_studio/re-re-run.py\", line 1582, in run\n",
      "    self.save()\n",
      "  File \"/teamspace/studios/this_studio/re-re-run.py\", line 1534, in save\n",
      "    json.dump(out, f, indent=2, ensure_ascii=False)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/json/__init__.py\", line 179, in dump\n",
      "    for chunk in iterable:\n",
      "                 ^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/json/encoder.py\", line 432, in _iterencode\n",
      "    yield from _iterencode_dict(o, _current_indent_level)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/json/encoder.py\", line 406, in _iterencode_dict\n",
      "    yield from chunks\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/json/encoder.py\", line 406, in _iterencode_dict\n",
      "    yield from chunks\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/json/encoder.py\", line 406, in _iterencode_dict\n",
      "    yield from chunks\n",
      "  [Previous line repeated 1 more time]\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/json/encoder.py\", line 439, in _iterencode\n",
      "    o = _default(o)\n",
      "        ^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/json/encoder.py\", line 180, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type bool_ is not JSON serializable\n",
      "Traceback (most recent call last):\n",
      "  File \"/teamspace/studios/this_studio/re-re-run.py\", line 1625, in <module>\n",
      "    MultilingualPipeline(cfg).run()\n",
      "  File \"/teamspace/studios/this_studio/re-re-run.py\", line 1582, in run\n",
      "    self.save()\n",
      "  File \"/teamspace/studios/this_studio/re-re-run.py\", line 1534, in save\n",
      "    json.dump(out, f, indent=2, ensure_ascii=False)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/json/__init__.py\", line 179, in dump\n",
      "    for chunk in iterable:\n",
      "                 ^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/json/encoder.py\", line 432, in _iterencode\n",
      "    yield from _iterencode_dict(o, _current_indent_level)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/json/encoder.py\", line 406, in _iterencode_dict\n",
      "    yield from chunks\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/json/encoder.py\", line 406, in _iterencode_dict\n",
      "    yield from chunks\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/json/encoder.py\", line 406, in _iterencode_dict\n",
      "    yield from chunks\n",
      "  [Previous line repeated 1 more time]\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/json/encoder.py\", line 439, in _iterencode\n",
      "    o = _default(o)\n",
      "        ^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/json/encoder.py\", line 180, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type bool_ is not JSON serializable\n"
     ]
    }
   ],
   "source": [
    "!python re-re-run.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68079e12-8091-485b-bdf2-1c50ebc6276e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
